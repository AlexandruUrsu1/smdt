###############################################################################
#   File: db.py
#   Author(s): Paul Johnecheck
#   Date Created: 11 April, 2021
#
#   Purpose: This is the class representing the database.
#    It will act as the main interface for reading and writing to the database. 
#
#   Known Issues:
#
#   Workarounds:
#
###############################################################################


# Import Preparation block.
# Currently only needed so the records in the mains work with the current imports.
import os
import sys

# Adds the folder that file is in to the system path
sMDT_DIR = os.path.dirname(os.path.abspath(__file__))
containing_dir = os.path.dirname(sMDT_DIR)
sys.path.append(sMDT_DIR)


from tube import Tube
from data.swage import SwageRecord
from data.tension import TensionRecord
from data.leak import LeakRecord
from data.dark_current import DarkCurrentRecord
import locks
import shelve
import pickle
import time
import datetime
import random
import re

class db:

    def __init__(self, db_path=os.path.join(containing_dir, "database.s")):
        '''
        Constructor, builds the database object. Gets the path to the database
        '''
        self.path = db_path
        
    def size(self):
        '''
        Return the integer size of the database. May wait for the database to be unlocked
        '''
        db_lock = locks.Lock("database")
        db_lock.wait()
        tubes = shelve.open(self.path)
        ret_size = len(tubes)
        tubes.close()
        return ret_size
        
       
    def add_tube(self, tube: Tube()):
        '''
        Adds tube to the database. It does so by pickling the tube,
        and adding it to the new_data file for the database manager to add to the database with update()
        '''
        
        dt = datetime.datetime.now()
        timestamp = dt.timestamp()

        filename = str(timestamp) + str(random.randrange(0,999)) + ".tube"


        new_data_path = os.path.join(sMDT_DIR, "new_data")
        
        if not os.path.isdir(new_data_path):
            os.mkdir(new_data_path)

        file_lock = locks.Lock(filename)
        file_lock.lock()
        with open(os.path.join(new_data_path, filename),"wb") as f:
            pickle.dump(tube, f)
        file_lock.unlock()

    def get_tube(self, id):
        '''
        Returns the tube specified by id. May wait for the database to be unlocked.
        '''
        db_lock = locks.Lock("database")
        db_lock.wait()
        tubes = shelve.open(self.path)
        try:
            ret_tube = tubes[id]
        except KeyError:
            tubes.close()
            raise KeyError
        tubes.close()
        return ret_tube

    


#This object will eventually be moved to the legacy class.
class station_pickler:
    '''
    This class is designed to facilitate the interface between the database manager and the data generated by the stations. 
    This class will take whatever data is generated in the form of a csv file, and will read it into a sMDT tube object. 
    It will then pickle the object into the standard specified for new data for the db manager.
    '''
    def __init__(self, path):
        '''
        Constructor, builds the pickler object. Gets the path to the directory it should look for/create the relevant files in
        '''
        self.path = path 
        self.error_files = {'Swage' : set(), 'Tension' : set(), 'Leak' : set(), 'DarkCurrent' : set()}

    def write_errors(self):
        fp = open("errors.txt", 'a')
        for station in self.error_files:
            if self.error_files[station]:
                fp.write(station + ':\n')
                for filename in self.error_files[station]:
                    fp.write('\t' + filename + '\n')
        fp.close()

    '''
    This is the swage pickler function that will pickle every 
    swage csv file that is in the specified directory swagerDirectory
    '''
    def pickle_swage(self):
        swage_directory = os.path.join(self.path, "SwagerStation")
        archive_directory = os.path.join(swage_directory, "archive")
        CSV_directory = os.path.join(swage_directory, "SwagerData")
        new_data_directory = os.path.join(sMDT_DIR, "new_data")

        for directory in [swage_directory, CSV_directory, archive_directory, new_data_directory]:
            if not os.path.isdir(directory):
                os.mkdir(directory)

        for filename in os.listdir(CSV_directory):
            with open(os.path.join(CSV_directory, filename)) as CSV_file, open(os.path.join(archive_directory, filename), 'a') as archive_file:
                for line in CSV_file.readlines():
                    archive_file.write(line)
                    line = line.split(',')
                    # Here are the different csv types, there have been 3 versions
                    # The currently used version that includes endplug type 'Protvino' or 'Munich'
                    endplug_type = None
                    if len(line) not in [9,8,3]:
                        self.error_files['Swage'].add(filename)
                        continue
                    if len(line) == 9:
                        barcode      = line[0].replace('\r\n', '')
                        rawLength    = float(line[1]) if line[1] != "" else None
                        swageLength  = float(line[2]) if line[2] != "" else None
                        sDate        = datetime.datetime.strptime(line[3], '%m.%d.%Y_%H_%M_%S')
                        cCode        = line[4]
                        eCode        = line[5]
                        comment      = line[6]
                        user         = line[7].replace('\r\n', '')

                        endplug_type = line[8]
                        
                    # An earlier version when endplug type wasn't recorded
                    elif len(line) == 8:
                        barcode     = line[0].replace('\r\n', '')
                        rawLength   = float(line[1]) if line[1] != "" else None
                        swageLength = float(line[2]) if line[2] != "" else None
                        sDate       = datetime.datetime.strptime(line[3], '%m.%d.%Y_%H_%M_%S')
                        cCode       = line[4]
                        eCode       = line[5]
                        comment     = line[6]
                        user        = line[7].replace('\r\n', '')
                    # This was the very first iteration where there were only 3 things recorded
                    else:
                        barcode     = line[0].replace('\r\n', '')
                        comment     = line[1]
                        user        = line[2].replace('\r\n', '')
                        rawLength   = None
                        swageLength = None                       
                        eCode       = None
                        cCode       = None
                        # Swager date was stored in the filename in this version
                        try:
                            sDate = datetime.datetime.strptime(filename, '%m.%d.%Y_%H_%M_%S.csv')
                        except ValueError:
                            sDate = None

                    tube = Tube()
                    tube.m_tube_id = barcode
                    tube.new_comment(comment)
                    tube.swage.add_record(SwageRecord(raw_length=rawLength,
                                                        swage_length=swageLength,
                                                        clean_code=cCode,
                                                        error_code=eCode,
                                                        date=sDate,
                                                        user=user))


                    if endplug_type:
                        tube.legacy_data['is_munich'] = endplug_type == "Munich"

                    pickled_filename = str(datetime.datetime.now().timestamp()) + 'swage.tube'

                    print("Pickling swage data for tube", barcode)

                    file_lock = locks.Lock(pickled_filename)
                    file_lock.lock()
                    with open(os.path.join(new_data_directory, pickled_filename),"wb") as f: 
                        pickle.dump(tube, f)
                    file_lock.unlock()


            os.remove(os.path.join(CSV_directory, filename))   


        
    '''
    This is the tension pickler function that will pickle every tension csv file 
    that is in the specified directory tensionDirectory
    '''
    def pickle_tension(self):
        tension_directory = os.path.join(self.path, "TensionStation")
        archive_directory = os.path.join(tension_directory, "archive")
        CSV_directory = os.path.join(tension_directory, "output")
        new_data_directory = os.path.join(sMDT_DIR, "new_data")

        for directory in [tension_directory, CSV_directory, archive_directory, new_data_directory]:
            if not os.path.isdir(directory):
                os.mkdir(directory)

        for filename in os.listdir(CSV_directory):
            with open(os.path.join(CSV_directory, filename)) as CSV_file, open(os.path.join(archive_directory, filename), 'a') as archive_file:
                for line in CSV_file.readlines():
                    if line in {',\n', ','} or line[0:11] == "Operator ID":
                        continue
                    archive_file.write(line)

                    line = line.split(',')
                    # Check there are 8 columns, else report to terminal
                    if len(line) == 8:
                        user        = line[0]
                        date        = line[1]
                        barcode     = line[2]
                        #not_used   = line[3]
                        #not_used   = line[4]
                        frequency   = float(line[5])
                        tension     = float(line[6])
                        #not_used   = line[7]
                    # Report to terminal unknown formats
                    else: 
                        print("File " + filename + " has a line with unknown format")
                        self.error_files['Tension'].add(filename)
                        continue

                    if barcode[0:3] != 'MSU':
                        self.error_files['Tension'].add(filename)
                        continue

                    try:
                        sDate = datetime.datetime.strptime(date, '%d.%m.%Y %H.%M.%S')
                    except ValueError:
                        sDate = None

                    # Create tube instance
                    tube = Tube()
                    tube.m_tube_id = barcode

                    print("Pickling tension data for tube", barcode)
                   
                    tube.tension.add_record(TensionRecord(tension=tension,
                                                          frequency=frequency,
                                                          date=sDate,
                                                          user=user))

                    pickled_filename = str(datetime.datetime.now().timestamp()) + 'tension.tube'

                    # Lock and write tube instance to pickle file
                    file_lock = locks.Lock(pickled_filename)
                    file_lock.lock()
                    with open(os.path.join(new_data_directory, pickled_filename),"wb") as f: 
                        pickle.dump(tube, f)
                    file_lock.unlock()


            os.remove(os.path.join(CSV_directory, filename))   
    


    '''
    This is the leak rate pickler function that will pickle every leak rate csv file 
    that is in the specified directory leakDirectory
    '''
    def pickle_leak(self):
        leak_directory = os.path.join(self.path, "LeakStation")
        CSV_directory = os.path.join(self.path, 'LeakDetector')
        archive_directory = os.path.join(leak_directory, "archive")
        
        new_data_directory = os.path.join(sMDT_DIR, "new_data")

        for directory in [leak_directory, CSV_directory, archive_directory, new_data_directory]:
            if not os.path.isdir(directory):
                os.mkdir(directory)

        for filename in os.listdir(CSV_directory):
            with open(os.path.join(CSV_directory, filename)) as CSV_file, open(os.path.join(archive_directory, filename), 'a') as archive_file:
                for line in CSV_file.readlines():
                    archive_file.write(line)
                    line = line.split('\t')
                    # Check there are 6 columns, else report to terminal
                    if len(line) == 6:
                        try:
                            leak        = float(line[0])
                            pressure    = line[1]  # Not used
                            pass_fail   = line[2]  # Useless
                            date        = line[3]
                            time1       = line[4]
                            user        = line[5]
                        except ValueError:
                            self.error_files['Leak'].add(filename)
                            continue
                    # Report to terminal unknown formats
                    else:
                        print("File " + filename + " has line with unknown format")
                        self.error_files['Leak'].add(filename)
                        continue


                    try:
                        sDate = datetime.datetime.strptime(date + time1, '%m/%d/%Y%I:%M %p')
                    except ValueError:
                        sDate = None

                  
                    barcode = filename.split('_')[0]

                    # Create tube instance
                    tube = Tube()
                    tube.m_tube_id = barcode
                    tube.leak.add_record(LeakRecord(leak_rate=leak,
                                                          date=sDate, user=user))

                    print("Pickling leak data for tube", barcode)

                    pickled_filename = str(datetime.datetime.now().timestamp()) + 'leak.tube'

                    # Lock and write tube instance to pickle file
                    file_lock = locks.Lock(pickled_filename)
                    file_lock.lock()
                    with open(os.path.join(new_data_directory, pickled_filename),"wb") as f: 
                        pickle.dump(tube, f)
                    file_lock.unlock()

            os.remove(os.path.join(CSV_directory, filename))   

    '''
    This is the dark current pickler function that will pickle every dark current csv file 
    that is in the specified directory darkcurrentDirectory
    '''
    def pickle_darkcurrent(self):

        darkcurrent_directory = os.path.join(self.path, "DarkCurrentStation")

        CSV_directory = os.path.join(self.path, 'DarkCurrent', '3015V Dark Current')
        archive_directory = os.path.join(darkcurrent_directory, "archive")
        
        new_data_directory = os.path.join(sMDT_DIR, "new_data")

        for directory in [darkcurrent_directory, CSV_directory, archive_directory, new_data_directory]:
            if not os.path.isdir(directory):
                os.mkdir(directory)

        for filename in os.listdir(CSV_directory):
            with open(os.path.join(CSV_directory, filename)) as CSV_file, open(os.path.join(archive_directory, filename), 'a') as archive_file:
                for line in CSV_file.readlines():
                    archive_file.write(line)
                    line = line.split(',')
                    # Check there are 2 columns, else report to terminal
                    if len(line) == 2:
                        current   = float(line[0])
                        date      = line[1]
                    # Report to terminal unknown formats
                    else:
                        print("File " + filename + " has unknown format")
                        self.error_files['DarkCurrent'].add(filename)
                        continue

                    try:
                        sDate = datetime.datetime.strptime(date, '%d_%m_%Y_%H_%M_%S\n')
                    except ValueError:
                        sDate = None

                    barcode = filename.split('.')[0]

                    # Create tube instance
                    tube = Tube()
                    tube.m_tube_id = barcode
                    tube.dark_current.add_record(DarkCurrentRecord(dark_current=current,
                                                          date=sDate))

                    print("Pickling dark current data for tube", barcode)

                    pickled_filename = str(datetime.datetime.now().timestamp()) + 'darkcurrent.tube'

                    # Lock and write tube instance to pickle file
                    file_lock = locks.Lock(pickled_filename)
                    file_lock.lock()
                    with open(os.path.join(new_data_directory, pickled_filename),"wb") as f: 
                        pickle.dump(tube, f)
                    file_lock.unlock()

            os.remove(os.path.join(CSV_directory, filename))


class db_manager():
    def __init__(self, db_path=os.path.join(os.path.dirname(sMDT_DIR), "database.s")):
        '''
        Constructor, builds the database manager object. Gets the path to the database
        '''
        self.path = db_path

    def wipe(self, confirm=False):
        '''
        Wipes the database. confirm must be "confirm" to proceed. 
        Excercise extreme caution with this, but it is necessary for many test cases.
        '''
        if confirm == 'confirm':
            db_lock = locks.Lock("database")
            db_lock.lock()

            tubes = shelve.open(self.path, flag='n')

            tubes.close()

            db_lock.unlock()

    def update(self):
        '''
        Updates the database by looking for .p files in the new_data directory.
        They should be pickled tubes, and they will be added to the database
        Needs to be ran after a db object calls add_tube(), otherwise the database will not contain the data in time for get_tube()
        '''

        dropbox_folder = os.path.dirname(sMDT_DIR)


        pickler = station_pickler(dropbox_folder)
        pickler.pickle_swage()
        pickler.pickle_tension()
        pickler.pickle_leak()
        pickler.pickle_darkcurrent()
        pickler.write_errors()



        #Lock the database
        db_lock = locks.Lock("database")
        db_lock.lock()


        new_data_path = os.path.join(sMDT_DIR, "new_data")

        with shelve.open(self.path) as tubes:

            count = 0
            for filename in os.listdir(new_data_path): 
                if filename.endswith(".tube"):
                    file_lock = locks.Lock(filename)
                    file_lock.wait()
                    new_data_file = open(os.path.join(new_data_path, filename), 'rb')   #open the file
                    tube = pickle.load(new_data_file)                                   #load the tube from pickle
                    new_data_file.close()                                               #close the file

                    print("Loading tube", tube.getID(), "into database.")

                    if tube.getID() in tubes:                                           #add the tubes to the database
                        temp = tubes[tube.getID()] + tube                           
                        tubes[tube.getID()] = temp                          
                    else:
                        tubes[tube.getID()] = tube
                    os.remove(os.path.join(new_data_path, filename))                 #delete the file that we added the tube from
                    count += 1
            print("Added", count, "tubes")

        #unlock the database
        db_lock.unlock()
